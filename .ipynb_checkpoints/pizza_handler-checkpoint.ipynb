{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "    \n",
    "14Apr15: *Changed Model's 'test' method to take the type of report as input. We should be using AUC most of the time (that is how the comp is scored) but might be useful to use classificaition report sometimes.\n",
    "*Classes start with caps, functions/methods in camel case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This cell's function:\n",
    "Import all libraries that will be needed throughout document\n",
    "'''\n",
    "\n",
    "# General libraries.\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from pprint import pprint\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# SK-learn libraries for feature extraction from text.\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4040, 3030, 1010)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Data_handler():\n",
    "    \n",
    "    if __name__ == \"__main__\":\n",
    "        dfTrain_full = pd.DataFrame()\n",
    "        dfTest = pd.DataFrame()\n",
    "        dfTrain = pd.DataFrame()\n",
    "        dfDev = pd.DataFrame()\n",
    "        trainColumnNames = []\n",
    "        testColumnNames = []\n",
    "    \n",
    "    def initialize_data(self,train_json, test_json, prop_train):\n",
    "        #Load in data as panda dataframes\n",
    "        with open(train_json,'r') as fp: \n",
    "            json_data = json.load(fp)\n",
    "        self.dfTrain_full = pd.io.json.json_normalize(json_data)\n",
    "\n",
    "        with open(test_json,'r') as fp: \n",
    "            json_data = json.load(fp)\n",
    "        self.dfTest = pd.io.json.json_normalize(json_data)\n",
    "\n",
    "        # Set np seed\n",
    "        np.random.seed(0)\n",
    "\n",
    "        #Shuffle train data and split into train and dev\n",
    "        self.dfTrain_full.reindex(np.random.permutation(self.dfTrain_full.index)) #shuffle\n",
    "        nTrain_full = self.dfTrain_full.shape[0]\n",
    "        self.dfTrain = self.dfTrain_full[:int(nTrain_full*prop_train)]\n",
    "        self.dfDev = self.dfTrain_full[int(nTrain_full*prop_train):]\n",
    "        \n",
    "        #Save number of observations in train and dev\n",
    "        nTrain = self.dfTrain.shape[0]\n",
    "        nDev = self.dfDev.shape[0]\n",
    "\n",
    "        #Save column names for reference\n",
    "        self.trainColumnNames = self.dfTrain.columns.tolist()\n",
    "        self.testColumnNames = self.dfTest.columns.tolist() #Note test features is only a subset!\n",
    "        \n",
    "        return nTrain_full, nTrain, nDev ################# WHY DOES THIS GET RETURNED? WHAT IS IT USED FOR?\n",
    "    \n",
    "    def getTrainFull(self):\n",
    "        return self.dfTrain_full   \n",
    "    def getTest(self):\n",
    "        return self.dfTest   \n",
    "    def getTrain(self):\n",
    "        return self.dfTrain   \n",
    "    def getDev(self):\n",
    "        return self.dfDev    \n",
    "    def getTrainColumnNames(self):\n",
    "        return self.trainColumnNames   \n",
    "    def getTestColumnNames(self):\n",
    "        return self.testColumnNames\n",
    "    \n",
    "# Load in our data to master_data. Proportion in train vs dev is set here. Changing it will take effect throughout everything else in the script (the magic of classes!)\n",
    "master_data = Data_handler()\n",
    "master_data.initialize_data('train.json', 'test.json',.75)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FeatureEngineer():\n",
    "    '''\n",
    "    Module that contains some of our feature engineering methods. \n",
    "    Does not contain instance variables!\n",
    "    '''\n",
    "    def separateTimestamp(self,df):\n",
    "        '''\n",
    "        separates time stamp (UTC) into month, day, hour. If user's local time is of interest, \n",
    "        use the non UTC data\n",
    "        input: any dataFrame containing the timestamp data\n",
    "        '''\n",
    "\n",
    "        timeStamps = df['unix_timestamp_of_request_utc'].values #numpy array of timestamps\n",
    "        timeStampsSeparate = [] #init new\n",
    "\n",
    "        # Loop over timestamps\n",
    "        for ts in timeStamps:\n",
    "            # Pull out relevant time info\n",
    "            month = datetime.datetime.fromtimestamp(ts).strftime(\"%m\")\n",
    "            day_of_month = datetime.datetime.fromtimestamp(ts).strftime(\"%d\")\n",
    "            hour = datetime.datetime.fromtimestamp(ts).strftime(\"%H\")\n",
    "            # Append to results\n",
    "            timeStampsSeparate.append([int(month),int(day_of_month),int(hour)])\n",
    "\n",
    "        #convert from python list to ndarray\n",
    "        return np.asarray(timeStampsSeparate)\n",
    "\n",
    "fe = FeatureEngineer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Model():\n",
    "    if __name__ == \"__main__\":\n",
    "        train_data = pd.DataFrame\n",
    "        test_data = pd.DataFrame\n",
    "        train_labels = np.array\n",
    "        prediction = np.array\n",
    "    \n",
    "    def init_test(self):\n",
    "        self.train_data = master_data.getTrain()\n",
    "        self.test_data = master_data.getDev()\n",
    "        self.prediction = np.zeros((len(self.test_data.values))) \n",
    "        self.train_labels = self.train_data['requester_received_pizza'].values\n",
    "    \n",
    "    def init_final(self):\n",
    "        self.train_data = master_data.getTrainFull()\n",
    "        self.test_data = master_data.getTest()\n",
    "        self.prediction = np.zeros((len(self.test_data.values)))\n",
    "        self.train_labels = self.train_data['requester_received_pizza'].values\n",
    "    \n",
    "    def test(self,criteria=metrics.roc_auc_score):\n",
    "        try:\n",
    "            dev_labels = self.test_data['requester_received_pizza'].values\n",
    "            return criteria(dev_labels,self.prediction)\n",
    "        except:\n",
    "            return \"Failed! Did you initialize as test? What criteria did you use?\"\n",
    "    \n",
    "    def finalize(self,fileName='submit_to_kaggle.csv'):\n",
    "        try:\n",
    "            '''\n",
    "            Ensure the test data hasn't been shuffled or your labels won't match the request_id's.\n",
    "            '''\n",
    "            #extract request_id so we can match against predictions for submission to kaggle\n",
    "            req = self.test_data['request_id']\n",
    "            #make prediction into a pandas series\n",
    "            print self.prediction.astype(int)\n",
    "            pred_series = pd.Series(self.prediction.astype(int),name=\"requester_received_pizza\")\n",
    "            #now join into data frame\n",
    "            out = pd.concat([req,pred_series], axis=1)\n",
    "            #write data frame to csv (using kaggles sample submission csv for correct format)\n",
    "            out.to_csv(fileName,index=False)\n",
    "        except:\n",
    "            return \"Failed! Did you initialize as final?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Baseline(Model):\n",
    "    '''\n",
    "    Any model just needs to implicitly inherit the model class\n",
    "    Test this with baseline.init_test() and baseline.test()\n",
    "    Generate output with baseline.init_final() and baseline.finalize()\n",
    "    \n",
    "    This is the first model we submitted to Kaggle\n",
    "    '''\n",
    "\n",
    "    def run_model(self):\n",
    "        train = self.train_data['request_text_edit_aware'].values\n",
    "        test = self.test_data['request_text_edit_aware'].values\n",
    "        v_train, v_test = self.vectorize(train,test)\n",
    "        self.prediction = self.log_reg(v_train,v_test)\n",
    "\n",
    "    def vectorize(self,train,test):\n",
    "        # transform the train data\n",
    "        vectorizer_train = CountVectorizer()\n",
    "        v_train = vectorizer_train.fit_transform(train)\n",
    "        vocab_train = vectorizer_train.get_feature_names()\n",
    "        # transform the dev data using the same vocab\n",
    "        v_test = vectorizer_train.transform(test)     # 'transform' function will preserve previous vocab\n",
    "        return v_train, v_test\n",
    "\n",
    "    def log_reg(self,v_train,v_test):\n",
    "        lor = LogisticRegression()\n",
    "        lor.fit(v_train, self.train_labels)\n",
    "        lor_pred = lor.predict(v_test)\n",
    "        # Return the prediction matrix, coefficients\n",
    "        return lor_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "class NumericModel(Model):\n",
    "    '''\n",
    "    Simple models with numeric data straight out of df\n",
    "    '''\n",
    "    def run_model(self):\n",
    "        colNames = [master_data.getTestColumnNames()[i] for i in [5,7,8,9]] #hand picked to be plausible \n",
    "        #numeric data\n",
    "        train_num = self.train_data[colNames].values\n",
    "        test_num = self.test_data[colNames].values\n",
    "        #convert time stamp into nice format\n",
    "        train_time = fe.separateTimestamp(self.train_data)\n",
    "        test_time = fe.separateTimestamp(self.test_data)\n",
    "        #merge\n",
    "        train = np.column_stack((train_num,train_time))\n",
    "        test = np.column_stack((test_num,test_time))\n",
    "        #predict\n",
    "        self.prediction = self.classify(train,test)    \n",
    "    \n",
    "    def classify(self,train,test):\n",
    "        nb = GaussianNB()\n",
    "        print train\n",
    "        nb.fit(train, self.train_labels)\n",
    "        return nb.predict(test) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'giver_username_if_known',\n",
      " u'number_of_downvotes_of_request_at_retrieval',\n",
      " u'number_of_upvotes_of_request_at_retrieval',\n",
      " u'post_was_edited',\n",
      " u'request_id',\n",
      " u'request_number_of_comments_at_retrieval',\n",
      " u'request_text',\n",
      " u'request_text_edit_aware',\n",
      " u'request_title',\n",
      " u'requester_account_age_in_days_at_request',\n",
      " u'requester_account_age_in_days_at_retrieval',\n",
      " u'requester_days_since_first_post_on_raop_at_request',\n",
      " u'requester_days_since_first_post_on_raop_at_retrieval',\n",
      " u'requester_number_of_comments_at_request',\n",
      " u'requester_number_of_comments_at_retrieval',\n",
      " u'requester_number_of_comments_in_raop_at_request',\n",
      " u'requester_number_of_comments_in_raop_at_retrieval',\n",
      " u'requester_number_of_posts_at_request',\n",
      " u'requester_number_of_posts_at_retrieval',\n",
      " u'requester_number_of_posts_on_raop_at_request',\n",
      " u'requester_number_of_posts_on_raop_at_retrieval',\n",
      " u'requester_number_of_subreddits_at_request',\n",
      " u'requester_received_pizza',\n",
      " u'requester_subreddits_at_request',\n",
      " u'requester_upvotes_minus_downvotes_at_request',\n",
      " u'requester_upvotes_minus_downvotes_at_retrieval',\n",
      " u'requester_upvotes_plus_downvotes_at_request',\n",
      " u'requester_upvotes_plus_downvotes_at_retrieval',\n",
      " u'requester_user_flair',\n",
      " u'requester_username',\n",
      " u'unix_timestamp_of_request',\n",
      " u'unix_timestamp_of_request_utc']\n",
      "\n",
      "\n",
      "request_text_edit_aware\n",
      "request_title\n",
      "\n",
      "\n",
      "                             request_text_edit_aware  \\\n",
      "0  Hi I am in need of food for my 4 children we a...   \n",
      "1  I spent the last money I had on gas today. Im ...   \n",
      "2  My girlfriend decided it would be a good idea ...   \n",
      "3  It's cold, I'n hungry, and to be completely ho...   \n",
      "4  hey guys:\\n I love this sub. I think it's grea...   \n",
      "\n",
      "                                       request_title  \n",
      "0            Request Colorado Springs Help Us Please  \n",
      "1  [Request] California, No cash and I could use ...  \n",
      "2  [Request] Hungry couple in Dundee, Scotland wo...  \n",
      "3  [Request] In Canada (Ontario), just got home f...  \n",
      "4  [Request] Old friend coming to visit. Would LO...  \n",
      "\n",
      "\n",
      "<type 'numpy.ndarray'>\n",
      "(3030L, 2L)\n",
      "\n",
      "\n",
      "(3030L,)   (1010L,)   (4040L,)\n",
      "\n",
      "\n",
      "(3030L,)   (3030L,)   (3030L, 2L)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nTo use:\\n1) instantiate your model class\\n2) initialize it as either test or final\\n3) run it and either test or finalize it\\n\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "TUTORIAL: This cell shows how the dataframes above get accessed and turned into usable numpy arrays\n",
    "'''\n",
    "\n",
    "###Task: Extracting message text AND title text into a feature vector:\n",
    "#first find name of column by printing out the list of names\n",
    "trainColumnNames = master_data.getTrainColumnNames()\n",
    "pprint(trainColumnNames) #looks like we want 'request_text_edit_aware' and 'request_title'\n",
    "#find which number this is or manually type column name\n",
    "print '\\n'\n",
    "print trainColumnNames[7]\n",
    "print trainColumnNames[8]\n",
    "\n",
    "#two ways to get data we want:\n",
    "print '\\n'\n",
    "X_train = master_data.getTrain()[['request_text_edit_aware','request_title']] #method 1\n",
    "X_train = master_data.getTrain()[[trainColumnNames[7],trainColumnNames[8]]] #method 2\n",
    "print X_train.head() #.head() just prints the first 5 rows\n",
    "\n",
    "#The above X_train is still a pandas dataframe. Converting to numpy array for sklearn is as simple as:\n",
    "print '\\n'\n",
    "X_train = X_train.values\n",
    "print type(X_train)\n",
    "print X_train.shape\n",
    "\n",
    "#In summary (quick way):\n",
    "X_train = master_data.getTrain()[['request_text_edit_aware','request_title']].values \n",
    "\n",
    "###Task: Join 2 numpy arrays horizontally (e.g. merge train and dev for final submission)\n",
    "train_data = master_data.getTrain()['request_text_edit_aware'].values\n",
    "dev_data = master_data.getDev()['request_text_edit_aware'].values\n",
    "merged_data = np.concatenate((train_data,dev_data),axis=0)\n",
    "print '\\n'\n",
    "print train_data.shape,' ',dev_data.shape,' ',merged_data.shape\n",
    "\n",
    "###Task: Join 2 numpy arrays vertically (e.g. add a bunch of features)\n",
    "train_data1 = master_data.getTrain()['request_text_edit_aware'].values\n",
    "#now we want more features... say from some feature engineering process\n",
    "train_data2 = master_data.getTrain()['request_title'].values\n",
    "train_data_merged = np.column_stack((train_data1,train_data2)) #<---- where the action is at!\n",
    "print '\\n'\n",
    "print train_data1.shape,' ',train_data2.shape,' ',train_data_merged.shape\n",
    "\n",
    "###Task: Use the Classes\n",
    "'''\n",
    "To use:\n",
    "1) instantiate your model class\n",
    "2) initialize it as either test or final\n",
    "3) run it and either test or finalize it\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "baseline_model = Baseline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.55160457863\n"
     ]
    }
   ],
   "source": [
    "# Run test of baseline\n",
    "baseline_model.init_test()\n",
    "baseline_model.run_model()\n",
    "print baseline_model.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ..., 0 1 0]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Run final of baseline\n",
    "baseline_model.init_final()\n",
    "baseline_model.run_model()\n",
    "print baseline_model.finalize('test_finalize.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.          0.          0.        ...,  10.          6.          8.       ]\n",
      " [  0.          0.         15.        ...,   3.         25.         15.       ]\n",
      " [  0.          0.          0.        ...,  10.         27.          3.       ]\n",
      " ..., \n",
      " [  3.8171412   1.          0.        ...,  10.          2.          8.       ]\n",
      " [  0.          0.          0.        ...,   6.         21.          1.       ]\n",
      " [  0.          0.          0.        ...,   7.         22.         15.       ]]\n",
      "0.528009541451\n"
     ]
    }
   ],
   "source": [
    "#Run NumericModel\n",
    "numeric_model = NumericModel()\n",
    "numeric_model.init_test()\n",
    "numeric_model.run_model()\n",
    "print numeric_model.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
