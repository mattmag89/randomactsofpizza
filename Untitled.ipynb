{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset and extracting TF-IDF features...\n",
      "done in 1.967s.\n",
      "Fitting the NMF model with n_samples=1000 and n_features=600...\n",
      "done in 448.793s.\n",
      "Topic #0:\n",
      "think don pretty list switch win easy going opinion yes early general com appears unless large left add hp case\n",
      "\n",
      "Topic #1:\n",
      "edu soon internet send com home mit good university cs robert address need info mail post years reply ftp sun\n",
      "\n",
      "Topic #2:\n",
      "car good year cars bike power new insurance buy got great small used light time ve stop started like years\n",
      "\n",
      "Topic #3:\n",
      "thanks know mail advance interested hi email does list com want send help anybody post info like net tell reply\n",
      "\n",
      "Topic #4:\n",
      "windows problem software using drive use file card help window monitor dos work pc application files version available drivers disk\n",
      "\n",
      "Topic #5:\n",
      "just ll heard sure new does thought got like thing want mean way read bit doesn maybe bad say right\n",
      "\n",
      "Topic #6:\n",
      "key chip clipper government encryption keys use phone public law standard doesn court yes legal going data used user right\n",
      "\n",
      "Topic #7:\n",
      "people don like know time say ve israel years really evidence did government rights food long make probably way lot\n",
      "\n",
      "Topic #8:\n",
      "game win team said goal better good year red time left defense does looking 10 shot mean doesn run best\n",
      "\n",
      "Topic #9:\n",
      "god jesus life christ christian bible mary believe good religion book point accept human love nature deleted children does death\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\decomposition\\nmf.py:533: UserWarning: Iteration limit reached during fit\n",
      "  warnings.warn(\"Iteration limit reached during fit\")\n"
     ]
    }
   ],
   "source": [
    "# Author: Olivier Grisel <olivier.grisel@ensta.org>\n",
    "#         Lars Buitinck <L.J.Buitinck@uva.nl>\n",
    "#http://scikit-learn.org/stable/auto_examples/applications/topics_extraction_with_nmf.html\n",
    "# License: BSD 3 clause\n",
    "\n",
    "from __future__ import print_function\n",
    "from time import time\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "n_samples = 1000\n",
    "n_features = 600\n",
    "n_topics = 10\n",
    "n_top_words = 20\n",
    "\n",
    "# Load the 20 newsgroups dataset and vectorize it. We use a few heuristics\n",
    "# to filter out useless terms early on: the posts are stripped of headers,\n",
    "# footers and quoted replies, and common English words, words occurring in\n",
    "# only one document or in at least 95% of the documents are removed.\n",
    "\n",
    "t0 = time()\n",
    "print(\"Loading dataset and extracting TF-IDF features...\")\n",
    "dataset = fetch_20newsgroups(shuffle=True, random_state=1,\n",
    "                             remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, max_features=n_features,\n",
    "                             stop_words='english')\n",
    "tfidf = vectorizer.fit_transform(dataset.data[:n_samples])\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "# Fit the NMF model\n",
    "print(\"Fitting the NMF model with n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "nmf = NMF(n_components=n_topics, random_state=1).fit(tfidf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "for topic_idx, topic in enumerate(nmf.components_):\n",
    "    print(\"Topic #%d:\" % topic_idx)\n",
    "    print(\" \".join([feature_names[i]\n",
    "                    for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
