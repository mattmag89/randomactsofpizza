{
 "metadata": {
  "name": "",
  "signature": "sha256:ee3fd12b7256361168e5657bb7da09222d9bb3368e9b0021248f5d9d66b14499"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# This tells matplotlib not to try opening a new window for each plot.\n",
      "%matplotlib inline\n",
      "\n",
      "# General libraries.\n",
      "import re\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import json\n",
      "from pprint import pprint\n",
      "\n",
      "# SK-learn libraries for learning.\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.naive_bayes import BernoulliNB\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "\n",
      "# SK-learn libraries for evaluation.\n",
      "from sklearn.metrics import confusion_matrix\n",
      "from sklearn import metrics\n",
      "from sklearn.metrics import classification_report\n",
      "\n",
      "# SK-learn libraries for feature extraction from text.\n",
      "from sklearn.feature_extraction.text import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_dataset = 'train.json'\n",
      "test_dataset = 'test.json'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def separate_data(dataset):\n",
      "    data_target=[]\n",
      "    data_elements=[]\n",
      "    data_full=[]\n",
      "    data_msgtxt=[]\n",
      "\n",
      "    for element in dataset[0]:\n",
      "        if element != 'requester_received_pizza':\n",
      "            data_elements.append(element)\n",
      "\n",
      "    for request in dataset:\n",
      "        parts = []\n",
      "        data_msgtxt.append(request['request_text_edit_aware'])\n",
      "        if request['requester_received_pizza'] == True:\n",
      "            data_target.append(1)\n",
      "        else:\n",
      "            data_target.append(0)\n",
      "        for element in data_elements:\n",
      "            parts.append(request[element])\n",
      "        data_full.append(parts)\n",
      "\n",
      "    #pprint(msgtxt[0:3])\n",
      "    #pprint(data_elements)\n",
      "    #pprint(data_full[0])\n",
      "    return data_target, data_msgtxt, data_elements, data_full"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "raw_data=json.loads(open(train_dataset).read())\n",
      "num_test = len(raw_data)\n",
      "train_raw_data=raw_data[num_test/4:]\n",
      "dev_raw_data=raw_data[:num_test/4]\n",
      "train_target, train_msgtxt, train_elements, train_full = separate_data(train_raw_data)\n",
      "dev_target, dev_msgtxt, dev_elements, dev_full = separate_data(dev_raw_data)\n",
      "print num_test\n",
      "print len(train_target)\n",
      "print len(dev_target)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "4040\n",
        "3030\n",
        "1010\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def vectorize(train_data,dev_data):\n",
      "    # transform the train data\n",
      "    vectorizer_train = CountVectorizer()\n",
      "    v_data_train = vectorizer_train.fit_transform(train_data)\n",
      "    vocab_train = vectorizer_train.get_feature_names()\n",
      "    # transform the dev data using the same vocab\n",
      "    vectorizer_dev = CountVectorizer(vocabulary=vocab_train)\n",
      "    v_data_dev = vectorizer_dev.fit_transform(dev_data)\n",
      "    return v_data_train, v_data_dev, vocab_train"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def vectorize_bigram(train_data,dev_data):\n",
      "    # transform the train data\n",
      "    vectorizer_train = CountVectorizer(ngram_range=(2,2))\n",
      "    v_data_train = vectorizer_train.fit_transform(train_data)\n",
      "    vocab_train = vectorizer_train.get_feature_names()\n",
      "    # transform the dev data using the same vocab\n",
      "    vectorizer_dev = CountVectorizer(ngram_range=(2,2),vocabulary=vocab_train)\n",
      "    v_data_dev = vectorizer_dev.fit_transform(dev_data)\n",
      "    return v_data_train, v_data_dev, vocab_train"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Get attributes using nnz and shape\n",
      "def vectorizer_attrs(v_data):\n",
      "    nonzero = v_data.nnz\n",
      "    examples = v_data.shape[0]\n",
      "    distinct_words = v_data.shape[1]\n",
      "    avg_nonzero = float(nonzero)/examples\n",
      "    total_entries = examples*distinct_words\n",
      "    pct_nz_entries = float(nonzero)/total_entries*100\n",
      "    return \"Vocabulary size: \" + str(distinct_words) + \"\\nAverage non-zero features per example: \" + str(round(avg_nonzero,1)) + \"\\nFraction of non-zero entries in the matrix is \" + str(nonzero) + \"/\" + str(total_entries) + \" (\" + str(round(pct_nz_entries,2)) + \"%)\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def log_reg(train_data,train_label,dev_data,dev_label):\n",
      "    lor = LogisticRegression()\n",
      "    lor.fit(train_data, train_label)\n",
      "    lor_pred = lor.predict(dev_data)\n",
      "    allcoefs = lor.coef_.copy()\n",
      "    f1scr = metrics.f1_score(dev_label,lor_pred)\n",
      "    # Return the prediction matrix, coefficients, and f1 score\n",
      "    return lor_pred, allcoefs, f1scr"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_topn(top_n,lorcoefs,vocab):\n",
      "    allcoefs = lorcoefs.copy()\n",
      "    lbls=allcoefs.shape[0]\n",
      "    index=[]\n",
      "    words=[]\n",
      "    for num in range(top_n):\n",
      "        mxindex = allcoefs.argmax(axis=1)\n",
      "        for lbl in range(lbls):\n",
      "            allcoefs[lbl][mxindex[lbl]] = 0\n",
      "            index.append(mxindex[lbl])\n",
      "            words.append(vocab[mxindex[lbl]])\n",
      "    # With our new index of the top n words in each label, get the coefficient matrix of these words\n",
      "    coefs=np.zeros((len(index),lbls))\n",
      "    for lbl in range(lbls):\n",
      "        for element in range(len(index)):\n",
      "            coefs[element][lbl] = lorcoefs[lbl][index[element]]\n",
      "    return words, coefs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_vdata, dev_vdata, vocab = vectorize(train_msgtxt, dev_msgtxt)\n",
      "prediction, allcoefs, f1 = log_reg(train_vdata,train_target,dev_vdata,dev_target)\n",
      "words, coefs = get_topn(10,allcoefs, vocab)\n",
      "print vectorizer_attrs(train_vdata)\n",
      "print f1\n",
      "print words\n",
      "print coefs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Vocabulary size: 10556\n",
        "Average non-zero features per example: 53.4\n",
        "Fraction of non-zero entries in the matrix is 161815/31984680 (0.51%)\n",
        "0.239024390244\n",
        "[u'sunday', u'father', u'quick', u'fault', u'hurting', u'loves', u'rice', u'married', u'interview', u'putting']\n",
        "[[ 1.36888607]\n",
        " [ 1.20720928]\n",
        " [ 1.12295207]\n",
        " [ 1.11173894]\n",
        " [ 1.08595615]\n",
        " [ 1.03481269]\n",
        " [ 0.98566098]\n",
        " [ 0.94101458]\n",
        " [ 0.9403405 ]\n",
        " [ 0.92768282]]\n"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}