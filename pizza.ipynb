{
 "metadata": {
  "name": "",
  "signature": "sha256:3324e33c9acb7ea9234a709d2ce240acfadd37e165ce9ed4f5ca21020ca276c8"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# This tells matplotlib not to try opening a new window for each plot.\n",
      "%matplotlib inline\n",
      "\n",
      "# General libraries.\n",
      "import re\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import json\n",
      "from pprint import pprint\n",
      "import datetime\n",
      "\n",
      "# SK-learn libraries for learning.\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.naive_bayes import BernoulliNB\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "\n",
      "# SK-learn libraries for evaluation.\n",
      "from sklearn.metrics import confusion_matrix\n",
      "from sklearn import metrics\n",
      "from sklearn.metrics import classification_report\n",
      "\n",
      "# SK-learn libraries for feature extraction from text.\n",
      "from sklearn.feature_extraction.text import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 112
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_dataset = 'train.json'\n",
      "test_dataset = 'test.json'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 83
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def separate_data(dataset,data_type):\n",
      "    data_features=[]\n",
      "    data_msgtxt=[]\n",
      "    data_titletxt=[]\n",
      "    data_subreddits=[]\n",
      "    data_ts=[]\n",
      "    \n",
      "    if data_type == 'train':\n",
      "        data_target=[]\n",
      "    \n",
      "    '''\n",
      "    for element in predict_dataset[0]:\n",
      "        data_elements.append(element)\n",
      "    '''\n",
      "    \n",
      "    for request in dataset:\n",
      "        parts = []\n",
      "        \n",
      "        data_msgtxt.append(request['request_text_edit_aware'])\n",
      "        data_titletxt.append(request['request_title'])\n",
      "        data_subreddits.append(request['requester_subreddits_at_request'])\n",
      "        \n",
      "        month = datetime.datetime.fromtimestamp(request['unix_timestamp_of_request']).strftime(\"%m\")\n",
      "        day_of_month = datetime.datetime.fromtimestamp(request['unix_timestamp_of_request']).strftime(\"%d\")\n",
      "        hour = datetime.datetime.fromtimestamp(request['unix_timestamp_of_request']).strftime(\"%H\")\n",
      "        #rqst_ts = [int(month),int(day_of_month),int(hour)]\n",
      "        rqst_ts = [int(hour)]\n",
      "        \n",
      "        if data_type == 'train':\n",
      "            if request['requester_received_pizza'] == True:\n",
      "                data_target.append(1)\n",
      "            else:\n",
      "                data_target.append(0)\n",
      "        \n",
      "        for element in data_elements:\n",
      "            parts.append(request[element])\n",
      "        \n",
      "        data_features.append(parts)\n",
      "        data_ts.append(rqst_ts)\n",
      "    \n",
      "    if data_type == 'train':\n",
      "        return data_target, data_msgtxt, data_titletxt, data_subreddits, data_features, data_ts\n",
      "    else:\n",
      "        return data_msgtxt, data_titletxt, data_subreddits, data_features, data_ts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 165
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_data = json.loads(open(train_dataset).read())\n",
      "test_data = json.loads(open(test_dataset).read())\n",
      "\n",
      "data_elements=[u'requester_days_since_first_post_on_raop_at_request', u'requester_account_age_in_days_at_request', u'requester_number_of_posts_on_raop_at_request', u'requester_number_of_posts_at_request', u'requester_upvotes_plus_downvotes_at_request', u'requester_number_of_comments_at_request', u'requester_upvotes_minus_downvotes_at_request',u'requester_number_of_comments_in_raop_at_request',u'requester_number_of_subreddits_at_request']\n",
      "\n",
      "num_train = len(train_data)\n",
      "train_raw_data=train_data[num_train/4:]\n",
      "dev_raw_data=train_data[:num_train/4]\n",
      "\n",
      "train_target, train_msgtxt, train_titletxt, train_subreddits, train_features, train_ts = separate_data(train_raw_data,'train')\n",
      "dev_target, dev_msgtxt, dev_titletxt, dev_subreddits, dev_features, dev_ts = separate_data(dev_raw_data, 'train')\n",
      "\n",
      "print num_train\n",
      "print len(train_target)\n",
      "\n",
      "pprint(data_elements)\n",
      "pprint(train_features[0])\n",
      "pprint(train_ts[0])\n",
      "pprint(train_target[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "4040\n",
        "3030\n",
        "[u'requester_days_since_first_post_on_raop_at_request',\n",
        " u'requester_account_age_in_days_at_request',\n",
        " u'requester_number_of_posts_on_raop_at_request',\n",
        " u'requester_number_of_posts_at_request',\n",
        " u'requester_upvotes_plus_downvotes_at_request',\n",
        " u'requester_number_of_comments_at_request',\n",
        " u'requester_upvotes_minus_downvotes_at_request',\n",
        " u'requester_number_of_comments_in_raop_at_request',\n",
        " u'requester_number_of_subreddits_at_request']\n",
        "[0.0, 431.98866898148145, 0, 168, 9260, 341, 3332, 0, 43]\n",
        "[14]\n",
        "0\n"
       ]
      }
     ],
     "prompt_number": 166
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def vectorize(train_data,dev_data):\n",
      "    # transform the train data\n",
      "    vectorizer_train = CountVectorizer()\n",
      "    #vectorizer_train = TfidfVectorizer()\n",
      "    v_data_train = vectorizer_train.fit_transform(train_data)\n",
      "    vocab_train = vectorizer_train.get_feature_names()\n",
      "    # transform the dev data using the same vocab\n",
      "    vectorizer_dev = CountVectorizer(vocabulary=vocab_train)\n",
      "    #vectorizer_dev = TfidfVectorizer(vocabulary=vocab_train)\n",
      "    v_data_dev = vectorizer_dev.fit_transform(dev_data)\n",
      "    return v_data_train, v_data_dev, vocab_train"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 127
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def vectorize_bigram(train_data,dev_data):\n",
      "    # transform the train data\n",
      "    vectorizer_train = CountVectorizer(ngram_range=(2,2))\n",
      "    v_data_train = vectorizer_train.fit_transform(train_data)\n",
      "    vocab_train = vectorizer_train.get_feature_names()\n",
      "    # transform the dev data using the same vocab\n",
      "    vectorizer_dev = CountVectorizer(ngram_range=(2,2),vocabulary=vocab_train)\n",
      "    v_data_dev = vectorizer_dev.fit_transform(dev_data)\n",
      "    return v_data_train, v_data_dev, vocab_train"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 128
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Get attributes using nnz and shape\n",
      "def vectorizer_attrs(v_data):\n",
      "    nonzero = v_data.nnz\n",
      "    examples = v_data.shape[0]\n",
      "    distinct_words = v_data.shape[1]\n",
      "    avg_nonzero = float(nonzero)/examples\n",
      "    total_entries = examples*distinct_words\n",
      "    pct_nz_entries = float(nonzero)/total_entries*100\n",
      "    return \"Vocabulary size: \" + str(distinct_words) + \"\\nAverage non-zero features per example: \" + str(round(avg_nonzero,1)) + \"\\nFraction of non-zero entries in the matrix is \" + str(nonzero) + \"/\" + str(total_entries) + \" (\" + str(round(pct_nz_entries,2)) + \"%)\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 129
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def log_reg(train_data,train_label,dev_data):\n",
      "    lor = LogisticRegression(penalty='l2',C=100)\n",
      "    lor.fit(train_data, train_label)\n",
      "    lor_pred = lor.predict(dev_data)\n",
      "    lor_pred_pr = lor.predict_proba(dev_data)\n",
      "    allcoefs = lor.coef_.copy()\n",
      "    # Return the prediction matrix, coefficients\n",
      "    return lor_pred, lor_pred_pr, allcoefs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 130
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_topn(top_n,lorcoefs,vocab):\n",
      "    allcoefs = lorcoefs.copy()\n",
      "    lbls=allcoefs.shape[0]\n",
      "    index=[]\n",
      "    words=[]\n",
      "    for num in range(top_n):\n",
      "        mxindex = allcoefs.argmax(axis=1)\n",
      "        for lbl in range(lbls):\n",
      "            allcoefs[lbl][mxindex[lbl]] = 0\n",
      "            index.append(mxindex[lbl])\n",
      "            words.append(vocab[mxindex[lbl]])\n",
      "    # With our new index of the top n words in each label, get the coefficient matrix of these words\n",
      "    coefs=np.zeros((len(index),lbls))\n",
      "    for lbl in range(lbls):\n",
      "        for element in range(len(index)):\n",
      "            coefs[element][lbl] = lorcoefs[lbl][index[element]]\n",
      "    return words, coefs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 131
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_vectorized_logreg(train,test):\n",
      "    train_vdata, dev_vdata, vocab = vectorize(train,test)\n",
      "    prediction, predict_pr, allcoefs = log_reg(train_vdata,train_target,dev_vdata)\n",
      "    words, coefs = get_topn(10,allcoefs, vocab)\n",
      "    print vectorizer_attrs(train_vdata)\n",
      "    #print prediction\n",
      "    return predict_pr[:,1]\n",
      "    #top 10 words and their coefficients\n",
      "    #print words\n",
      "    #print coefs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 132
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "msg_prob = get_vectorized_logreg(train_msgtxt, dev_msgtxt)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Vocabulary size: 10556\n",
        "Average non-zero features per example: 53.4\n",
        "Fraction of non-zero entries in the matrix is 161815/31984680 (0.51%)\n"
       ]
      }
     ],
     "prompt_number": 133
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "title_prob = get_vectorized_logreg(train_titletxt, dev_titletxt)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Vocabulary size: 3832\n",
        "Average non-zero features per example: 11.3\n",
        "Fraction of non-zero entries in the matrix is 34173/11610960 (0.29%)\n"
       ]
      }
     ],
     "prompt_number": 134
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1010\n"
       ]
      }
     ],
     "prompt_number": 135
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1010\n"
       ]
      }
     ],
     "prompt_number": 136
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0.0, 0.0, 0, 0, 0, 0, 0, 0, 0]\n",
        "['10', '05', '18']\n"
       ]
      }
     ],
     "prompt_number": 138
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 97
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feature_prediction, feature_predict_pr, feature_allcoefs = log_reg(train_features,train_target,dev_features)\n",
      "ts_prediction, ts_predict_pr, ts_allcoefs = log_reg(train_ts,train_target,dev_ts)\n",
      "print feature_predict_pr\n",
      "print ts_predict_pr"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.79120797  0.20879203]\n",
        " [ 0.76458161  0.23541839]\n",
        " [ 0.79120797  0.20879203]\n",
        " ..., \n",
        " [ 0.77608364  0.22391636]\n",
        " [ 0.78600322  0.21399678]\n",
        " [ 0.78588184  0.21411816]]\n",
        "[[ 0.75388208  0.24611792]\n",
        " [ 0.78420871  0.21579129]\n",
        " [ 0.76309099  0.23690901]\n",
        " ..., \n",
        " [ 0.75574299  0.24425701]\n",
        " [ 0.75759436  0.24240564]\n",
        " [ 0.75943616  0.24056384]]\n"
       ]
      }
     ],
     "prompt_number": 171
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "prediction_array=[]\n",
      "predict_score=[]\n",
      "score_val=0.1\n",
      "prediction=[]\n",
      "for i in range(len(dev_features)):\n",
      "    proba=[]\n",
      "    proba.append(msg_prob[i])\n",
      "    proba.append(title_prob[i])\n",
      "    proba.append(feature_predict_pr[i,1])\n",
      "    proba.append(ts_predict_pr[i,1])\n",
      "    prediction_array.append(proba)\n",
      "    predict_score.append(sum(proba))\n",
      "    if sum(proba)>=score_val:\n",
      "        prediction.append(1)\n",
      "    else:\n",
      "        prediction.append(0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 221
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"F1 score of final model is \" + str(round(metrics.f1_score(dev_target,prediction),3))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "F1 score of final model is 0.413\n"
       ]
      }
     ],
     "prompt_number": 222
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print prediction\n",
      "print dev_target"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
        "[0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1]\n"
       ]
      }
     ],
     "prompt_number": 225
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}