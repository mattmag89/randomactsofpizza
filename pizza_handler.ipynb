{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This cell's function:\n",
    "Import all libraries that will be needed throughout document\n",
    "'''\n",
    "\n",
    "# General libraries.\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from pprint import pprint\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# SK-learn libraries for feature extraction from text.\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4040, 3030, 1010)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class data_handler():\n",
    "    \n",
    "    if __name__ == \"__main__\":\n",
    "        dfTrain_full = pd.DataFrame()\n",
    "        dfTest = pd.DataFrame()\n",
    "        dfTrain = pd.DataFrame()\n",
    "        dfDev = pd.DataFrame()\n",
    "        trainColumnNames = []\n",
    "        testColumnNames = []\n",
    "    \n",
    "    def initialize_data(self,train_json, test_json, prop_train):\n",
    "        #Load in data as panda dataframes\n",
    "        with open(train_json,'r') as fp: \n",
    "            json_data = json.load(fp)\n",
    "        self.dfTrain_full = pd.io.json.json_normalize(json_data)\n",
    "\n",
    "        with open(test_json,'r') as fp: \n",
    "            json_data = json.load(fp)\n",
    "        self.dfTest = pd.io.json.json_normalize(json_data)\n",
    "\n",
    "        # Set np seed\n",
    "        np.random.seed(0)\n",
    "\n",
    "        #Shuffle train data and split into train and dev\n",
    "        self.dfTrain_full.reindex(np.random.permutation(self.dfTrain_full.index)) #shuffle\n",
    "        nTrain_full = self.dfTrain_full.shape[0]\n",
    "        self.dfTrain = self.dfTrain_full[:int(nTrain_full*prop_train)]\n",
    "        self.dfDev = self.dfTrain_full[int(nTrain_full*prop_train):]\n",
    "        \n",
    "        #Save number of observations in train and dev\n",
    "        nTrain = self.dfTrain.shape[0]\n",
    "        nDev = self.dfDev.shape[0]\n",
    "\n",
    "        #Save column names for reference\n",
    "        self.trainColumnNames = self.dfTrain.columns.tolist()\n",
    "        self.testColumnNames = self.dfTest.columns.tolist() #Note test features is only a subset!\n",
    "        \n",
    "        return nTrain_full, nTrain, nDev\n",
    "\n",
    "# Load in our data to master_data. Proportion in train vs dev is set here. Changing it will take effect throughout everything else in the script (the magic of classes!)\n",
    "master_data = data_handler()\n",
    "master_data.initialize_data('train.json', 'test.json',.75)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class model():\n",
    "    if __name__ == \"__main__\":\n",
    "        train_data = pd.DataFrame\n",
    "        test_data = pd.DataFrame\n",
    "        train_labels = np.array\n",
    "        prediction = np.array\n",
    "    \n",
    "    def init_test(self):\n",
    "        self.train_data = master_data.dfTrain\n",
    "        self.test_data = master_data.dfDev\n",
    "        self.prediction = np.zeros((len(self.test_data.values)))\n",
    "        self.train_labels = self.train_data['requester_received_pizza'].values\n",
    "    \n",
    "    def init_final(self):\n",
    "        self.train_data = master_data.dfTrain_full\n",
    "        self.test_data = master_data.dfTest\n",
    "        self.prediction = np.zeros((len(self.test_data.values)))\n",
    "        self.train_labels = self.train_data['requester_received_pizza'].values\n",
    "    \n",
    "    def test(self):\n",
    "        try:\n",
    "            dev_labels = self.test_data['requester_received_pizza'].values\n",
    "            return metrics.classification_report(dev_labels,self.prediction)\n",
    "        except:\n",
    "            return \"Failed! Did you initialize as test?\"\n",
    "    \n",
    "    def finalize(self,fileName='submit_to_kaggle.csv'):\n",
    "        try:\n",
    "            '''\n",
    "            Ensure the test data hasn't been shuffled or your labels won't match the request_id's.\n",
    "            '''\n",
    "            #extract request_id so we can match against predictions for submission to kaggle\n",
    "            req = self.test_data['request_id']\n",
    "            #make prediction into a pandas series\n",
    "            print self.prediction.astype(int)\n",
    "            pred_series = pd.Series(self.prediction.astype(int),name=\"requester_received_pizza\")\n",
    "            #now join into data frame\n",
    "            out = pd.concat([req,pred_series], axis=1)\n",
    "            #write data frame to csv (using kaggles sample submission csv for correct format)\n",
    "            out.to_csv(fileName,index=False)\n",
    "        except:\n",
    "            return \"Failed! Did you initialize as final?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class baseline(model):\n",
    "    '''\n",
    "    Any model just needs to implicitly inherit the model class\n",
    "    Test this with baseline.init_test() and baseline.test()\n",
    "    Generate output with baseline.init_final() and baseline.finalize()\n",
    "    '''\n",
    "\n",
    "    def run_model(self):\n",
    "        train = self.train_data['request_text_edit_aware'].values\n",
    "        test = self.test_data['request_text_edit_aware'].values\n",
    "        v_train, v_test = self.vectorize(train,test)\n",
    "        self.prediction = self.log_reg(v_train,v_test)\n",
    "\n",
    "    def vectorize(self,train,test):\n",
    "        # transform the train data\n",
    "        vectorizer_train = CountVectorizer()\n",
    "        v_train = vectorizer_train.fit_transform(train)\n",
    "        vocab_train = vectorizer_train.get_feature_names()\n",
    "        # transform the dev data using the same vocab\n",
    "        v_test = vectorizer_train.transform(test)     # 'transform' function will preserve previous vocab\n",
    "        return v_train, v_test\n",
    "\n",
    "    def log_reg(self,v_train,v_test):\n",
    "        lor = LogisticRegression()\n",
    "        lor.fit(v_train, self.train_labels)\n",
    "        lor_pred = lor.predict(v_test)\n",
    "        # Return the prediction matrix, coefficients\n",
    "        return lor_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1) look at my examples and figure out how to make superclasses work\\n2) implement superclass baseline(model)\\n3) make this script just something that gets called in to actual model scripts\\n\\n'"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "To use:\n",
    "1) instantiate your model class\n",
    "2) initialize it as either test or final\n",
    "3) run it and either test or finalize it\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "baseline_model = baseline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1010L,)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.78      0.85      0.81       761\n",
      "       True       0.36      0.25      0.30       249\n",
      "\n",
      "avg / total       0.67      0.70      0.68      1010\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run test of baseline\n",
    "baseline_model.init_test()\n",
    "baseline_model.run_model()\n",
    "print baseline_model.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ..., 0 1 0]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Run final of baseline\n",
    "baseline_model.init_final()\n",
    "baseline_model.run_model()\n",
    "print baseline_model.finalize('test_finalize.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
